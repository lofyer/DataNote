=======================
第四章 数据处理平台
=======================

某些时候当我们的数据量足够大时（前提是有很多服务器资源），单一的计算程序已经不能够满足数据处理的需求，所以我们引入了专门的数据处理平台以优化工作。

其实，对于一般用户而言，这些平台带来的价值是小于所投入的成本的。比如某些互联网公司的数据处理平台是在其多年磨合下才达到几分钟排序100TB的效率的，而开源的直接拿来用若想达到这个效率无异于痴人说梦。

OK，扯远了，那么对目前笔者数据量不到1TB的人来说，我就看看这些平台怎么工作的，流程有没有可取的地方，然后动手撸一个自己用的模型。

2018-10: 经过长期时间后，实践经验告诉我们，Hadoop之类的数据处理平台远远不足以称之为“平台”，所以本章内容将注重工具的组合，即架构，让读者能够“自己搭”。

----------------------
4.1 Hadoop与Spark简介
----------------------

Hadoop与现在更流行的Storm和Spark，从初学的角度来说更有价值。因为Hadoop内容不止有MapReduce，更有SQL式的Yarn和HDFS这一专为MR开发的文件系统，所以我认为在基础学习阶段它更具代表性。而Storm和Spark，它们的优劣我现在并不清楚，只知道前者适用于处理输入连绵数据，后者适用于复杂MR过程的模型。

-------------------------
4.2 模块部署（单机/集群）
-------------------------

现在部署Hadoop的方式比过去更加容易，你可以使用 `Cloudera Manager <http://www.cloudera.com/content/cloudera/en/downloads/cloudera_manager/cm-5-1-3.html>`_ 或者 Puppet 去完成企业级的部署；如果你需要概念证明类的工作，可以直接使用 `Hortonworks 的虚拟机镜像 <http://zh.hortonworks.com/products/hortonworks-sandbox/>`_ 或者 `Cloudera的虚拟机镜像 <http://www.cloudera.com/content/cloudera/en/downloads/quickstart_vms/cdh-5-1-x1.html>`_ ，或者 `MapR <https://www.mapr.com/products/mapr-sandbox-hadoop/download-sandbox-drill>`_ ，在接下来的章节中我会使用rpm包进行安装，而不是按照 `官方文档 <http://hadoop.apache.org/docs/r1.2.1/single_node_setup.html>`_ 去部署。

Hue：`Hadoop User Experience <http://gethue.com>`_ ，即web UI

单节点部署
===========

集群部署
==========

------------------
4.3. 数据处理目的
------------------

这里的数据是很原始的数据，即DIKW模型中的Data，我们的目的即是要Information以及Knowledge，及最后的Wisdom。

4.3.1. 数据降/增维（D）
=======================

4.3.2. 文本搜索引擎（I）
========================

4.3.3. 数据分类（I）
====================

4.3.4. 模型训练（K）
====================

4.3.5. 模拟（K）
=================

4.3.6. 模式识别（K）
====================

4.3.7 决策（W）
================
