

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-CN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-CN" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>第二章 机器学习基础 &mdash; Data Note  文档</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="第三章 ABM建模基础" href="ch03.html" />
    <link rel="prev" title="第一章 数据收集、统计" href="ch01.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> Data Note
          

          
          </a>

          
            
            
              <div class="version">
                0.8
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="ch01.html">第一章 数据收集、统计</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">第二章 机器学习基础</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#numpy">2.1 numpy 快查</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id2">2.2 监督学习</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id3">信息分类基础</a></li>
<li class="toctree-l3"><a class="reference internal" href="#k">K邻近算法</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id4">决策树</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id5">朴素贝叶斯</a></li>
<li class="toctree-l3"><a class="reference internal" href="#logistic">Logistic回归</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id7">线性回归</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id8">树回归</a></li>
<li class="toctree-l3"><a class="reference internal" href="#svm">SVM</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id10">神经网络</a></li>
<li class="toctree-l3"><a class="reference internal" href="#adaboost">AdaBoost</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id11">2.3 无监督学习</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id12">K-均值聚类</a></li>
<li class="toctree-l3"><a class="reference internal" href="#apriori">Apriori关联分析</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fp-growth">FP-growth发现高频项</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id13">2.4 数据可视化</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id14">数据统计</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id15">地理位置表示</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id16">2.5 学习工具</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#online">Online</a></li>
<li class="toctree-l3"><a class="reference internal" href="#gui">GUI</a></li>
<li class="toctree-l3"><a class="reference internal" href="#library">Library</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="ch03.html">第三章 ABM建模基础</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch04.html">第四章 数据处理平台</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch05.html">第五章 外汇交易基础</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch06.html">第六章 信号交易系统</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch07.html">第七章 指导白皮书</a></li>
<li class="toctree-l1"><a class="reference internal" href="about.html">关于</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Data Note</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>第二章 机器学习基础</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/posts/ch02.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="id1">
<h1>第二章 机器学习基础<a class="headerlink" href="#id1" title="永久链接至标题">¶</a></h1>
<div class="section" id="numpy">
<h2>2.1 numpy 快查<a class="headerlink" href="#numpy" title="永久链接至标题">¶</a></h2>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">data_type</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;name&#39;</span><span class="p">,</span><span class="s1">&#39;S10&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;height&#39;</span><span class="p">,</span> <span class="s1">&#39;float&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;age&#39;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)]</span>
<span class="n">values</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;Arthur&#39;</span><span class="p">,</span> <span class="mf">1.8</span><span class="p">,</span> <span class="mi">41</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;Lancelot&#39;</span><span class="p">,</span> <span class="mf">1.9</span><span class="p">,</span> <span class="mi">38</span><span class="p">),</span>
            <span class="p">(</span><span class="s1">&#39;Galahad&#39;</span><span class="p">,</span> <span class="mf">1.7</span><span class="p">,</span> <span class="mi">38</span><span class="p">)]</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">data_type</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># 符号</span>
<span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="c1"># 数组最大值</span>
<span class="n">a</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>

<span class="c1"># 数组最小值</span>
<span class="n">a</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>

<span class="c1"># 区间峰峰值</span>
<span class="n">a</span><span class="o">.</span><span class="n">ptp</span><span class="p">()</span>

<span class="c1"># 乘积</span>
<span class="n">a</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span>

<span class="c1"># 累积</span>
<span class="n">a</span><span class="o">.</span><span class="n">cumprod</span><span class="p">()</span>

<span class="c1"># 平均值</span>
<span class="n">a</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># 中值</span>
<span class="n">a</span><span class="o">.</span><span class="n">median</span><span class="p">()</span>

<span class="c1"># 差分</span>
<span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="c1"># 方差</span>
<span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="c1"># 元素条件查找，返回index的array</span>
<span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">a</span><span class="o">&gt;</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># 返回第2，3，5个元素的array</span>
<span class="n">np</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="c1"># 排序</span>
<span class="n">np</span><span class="o">.</span><span class="n">msort</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;mergesort&#39;</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">&#39;height&#39;</span><span class="p">)</span>

<span class="c1"># 均分，奇数个元素的array不可分割为偶数。</span>
<span class="n">np</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># 创建单位矩阵</span>
<span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># 最小二乘，参数为[x,y,degree]，degree为多项式的最高次幂，返回值为所有次幂的系数</span>
<span class="n">np</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="id2">
<h2>2.2 监督学习<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h2>
<div class="section" id="id3">
<h3>信息分类基础<a class="headerlink" href="#id3" title="永久链接至标题">¶</a></h3>
<p>信息的不稳定性为熵（entropy），而信息增益为有无样本特征对分类问题影响的大小。比如，抛硬币正反两面各有50%概率，此时不稳定性最大，熵为1；太阳明天照常升起，则是必然，此事不稳定性最小，熵为0。</p>
<p>假设事件X，发生概率为x，其信息期望值定义为：</p>
<div class="math notranslate nohighlight">
\[l(X) = -log_2 x\]</div>
<p>整个信息的熵为：</p>
<div class="math notranslate nohighlight">
\[H = -\sum^n_{i=1} log_2 x\]</div>
<p>如何找到最好的分类特征：</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span>def chooseBestFeatureToSplit(dataSet):
    numFeatures = len(dataSet[0]) - 1      #the last column is used for the labels
    baseEntropy = calcShannonEnt(dataSet)
    bestInfoGain = 0.0; bestFeature = -1
    for i in range(numFeatures):        #iterate over all the features
        featList = [example[i] for example in dataSet]#create a list of all the examples of this feature
        uniqueVals = set(featList)       #get a set of unique values
        newEntropy = 0.0
        for value in uniqueVals:
            subDataSet = splitDataSet(dataSet, i, value)
            prob = len(subDataSet)/float(len(dataSet))
            newEntropy += prob * calcShannonEnt(subDataSet)
        infoGain = baseEntropy - newEntropy     #calculate the info gain; ie reduction in entropy
        if (infoGain &gt; bestInfoGain):       #compare this to the best gain so far
            bestInfoGain = infoGain         #if better than current best, set to best
            bestFeature = i
    return bestFeature                      #returns an integer

其中，dataSet为所有特征向量，caclShannonEnt()计算特征向量的熵，splitDataSet()切除向量中的value列；infoGain即为信息增益，chooseBestFeatureToSplit返回最好的特征向量索引值。
</pre></div>
</div>
</div>
<div class="section" id="k">
<h3>K邻近算法<a class="headerlink" href="#k" title="永久链接至标题">¶</a></h3>
<p>kNN的算法模型如下：</p>
<p>对于未知类别属性的数据且集中的每个点依次执行以下操作：</p>
<ul class="simple">
<li>计算已知类别数据集中的点与当前点之间的距离</li>
<li>按照距离递增依次排序</li>
<li>选取与当前点距离最小的k个点</li>
<li>确定前k个点所在类别的出现频率</li>
<li>返回前k个点出现频率最高的类别作为当前点的预测分类</li>
</ul>
<p>代码参考如下：</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span>def classify0(inX, dataSet, labels, k):
    dataSetSize = dataSet.shape[0]
    diffMat = tile(inX, (dataSetSize,1)) - dataSet
    sqDiffMat = diffMat**2
    sqDistances = sqDiffMat.sum(axis=1)
    distances = sqDistances**0.5
    sortedDistIndicies = distances.argsort()
    classCount={}
    for i in range(k):
        voteIlabel = labels[sortedDistIndicies[i]]
        classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1
    sortedClassCount = sorted(classCount.iteritems(), key=operator.itemgetter(1), reverse=True)
    return sortedClassCount[0][0]

其中，inX为输入向量，dataSet为数据集，labels为数据集的分类，可调。距离计算公式为d0 = ((x-x0)**2 + (y-y0)**2)**0.5。
</pre></div>
</div>
<p>此种算法的优点为精度高、对异常值不敏感、但缺点也比较明显，即数据量大时开支相对较大，适用于数值－标称型数据。</p>
</div>
<div class="section" id="id4">
<h3>决策树<a class="headerlink" href="#id4" title="永久链接至标题">¶</a></h3>
<p>决策树即列出一系列选择，根据训练集中的大量形似（A、B、C）以及结果D的向量来预测新输入（A’、B’、C’）的结果D’。</p>
<p>首先创建一个决策树：</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span> def createTree(dataSet,labels):
     classList = [example[-1] for example in dataSet]
     if classList.count(classList[0]) == len(classList):
         return classList[0]     #stop splitting when all of the classes are equal
     if len(dataSet[0]) == 1:    #stop splitting when there are no more features in dataSet
         return majorityCnt(classList)
     bestFeat = chooseBestFeatureToSplit(dataSet)
     bestFeatLabel = labels[bestFeat]
     myTree = {bestFeatLabel:{}}
     del(labels[bestFeat])
     featValues = [example[bestFeat] for example in dataSet]
     uniqueVals = set(featValues)
     for value in uniqueVals:
         subLabels = labels[:]       #copy all of labels, so trees don&#39;t mess up existing labels
         myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value),subLabels)
     return myTree

 找到影响最大的特征bestFeat后，再创建此特征下的分类向量创建子树向量，然后将bestFeat分离后继续迭代，直至所有特征都转换成决策节点。

 原始数据比如：

     no-surfacing flippers  fish
 1       yes         yes     yes
 2       yes         yes     yes
 3       yes         no      no
 4       no          yes     no
 5       no          yes     no

 会生成如下决策树：

 no-surfacing?
     /    \
  no/      \yes
fish(no)  flippers?
            / \
         no/   \yes
     fish(no)  fish(yes)

 表示成JSON格式，即python字典：

 {&#39;no surfacing&#39;:{0:&#39;no&#39;,1:{&#39;flippers&#39;:{0:&#39;no&#39;,1:&#39;yes&#39;}}}

 构建决策树的方法比较多，也可使用C4.5和CART算法。
</pre></div>
</div>
<p>接下来使用决策树进行分类：</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span>def classify(inputTree,featLabels,testVec):
    firstStr = inputTree.keys()[0]
    secondDict = inputTree[firstStr]
    featIndex = featLabels.index(firstStr)
    key = testVec[featIndex]
    valueOfFeat = secondDict[key]
    if isinstance(valueOfFeat, dict):
        classLabel = classify(valueOfFeat, featLabels, testVec)
    else: classLabel = valueOfFeat
    return classLabel

其中，featLabels为测试的判断节点，即特征，testVec为其值，比如classify[myTree,&quot;[&#39;no-surfacing&#39;,&#39;flippers&#39;]&quot;,:[1,1]&quot;]，如此结果便为&#39;no&#39;。
</pre></div>
</div>
<p>使用pickle对决策树进行序列化存储：</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span> def storeTree(inputTree,filename):
     import pickle
     fw = open(filename,&#39;w&#39;)
     pickle.dump(inputTree,fw)
     fw.close()

其中，dump可选协议为0（ASCII），1（BINARY），默认为0；读取时使用pickle.load；同样可使用dumps，loads直接对字符变量进行操作。
</pre></div>
</div>
<p>此种算法计算复杂度不高，对中间值缺失不敏感，但可能会产生过拟合的问题。</p>
</div>
<div class="section" id="id5">
<h3>朴素贝叶斯<a class="headerlink" href="#id5" title="永久链接至标题">¶</a></h3>
<p>贝叶斯模型是基于独立概率统计的，思想可以这么说：</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span>总共7个石子在A、B两个桶中，A桶中有2黑2白，B桶中有2黑1白。已知条件为石子来自B桶，那么它是白色石子的概率可表示为：

    P(white|B)=P(B|white)P(white)/P(B)

接下来，定义两个事件A、B，P(A|B)与P(B|A)相互转化的过程即为：

    P(B|A)=P(A|B)P(B)/P(A)

而朴素贝叶斯可以这样描述：

设x={a1,a2,...,am}为待分类项，a为x的特征属性，类别集合为C={y1,y2,...,ym}，如果P(yk|x)=max(P(y1|x),P(y2|x),...,P(yn|x))，则x属于yk。

整个算法核心即是等式P(yi|x)=P(x|yi)P(yi)/P(x)。
</pre></div>
</div>
<p>首先构建一个分类训练函数（二元分类）：</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span>def trainNB0(trainMatrix,trainCategory):
    numTrainDocs = len(trainMatrix)
    numWords = len(trainMatrix[0])
    pBad = sum(trainCategory)/float(numTrainDocs)
    p0Num = ones(numWords); p1Num = ones(numWords)      #change to ones()
    p0Denom = 2.0; p1Denom = 2.0                        #change to 2.0
    for i in range(numTrainDocs):
        if trainCategory[i] == 1:
            p1Num += trainMatrix[i]
            p1Denom += sum(trainMatrix[i])
        else:
            p0Num += trainMatrix[i]
            p0Denom += sum(trainMatrix[i])
    p1Vect = log(p1Num/p1Denom)          #change to log()
    p0Vect = log(p0Num/p0Denom)          #change to log()
    return p0Vect,p1Vect,pBad

其中，trainMatrix为所有训练集中的布尔向量，比如两本书A、B，其中A有两个单词x、y，B有两个单词x、z，并且A是好书（值计为0），B是烂书（值计为0），把所有单词进行排序后得向量[&#39;x&#39;,&#39;y&#39;,&#39;z&#39;]，则A的Matrix可表示为[1,1,0]，B的为[1,0,1]，所以此函数中的trainMatrix即[[1,1,0],[1,0,1]]，trainCategory为[0,1]。
函数返回的为概率集的向量。
</pre></div>
</div>
<p>分类函数：</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span>def classifyNB(vec2Classify, p0Vec, p1Vec, pClass1):
    p1 = sum(vec2Classify * p1Vec) + log(pClass1)    #element-wise mult
    p0 = sum(vec2Classify * p0Vec) + log(1.0 - pClass1)
    if p1 &gt; p0:
        return 1
    else:
        return 0

vec2Classify即为要分类的向量，形如trainMatrix，随后的三个参数为trainNB0所返回。p1、p0可以理解为期望概率值，比较两者大小即可划分。
</pre></div>
</div>
<p>测试用例：</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">testingNB</span><span class="p">():</span>
    <span class="n">listOPosts</span><span class="p">,</span><span class="n">listClasses</span> <span class="o">=</span> <span class="n">loadDataSet</span><span class="p">()</span>
    <span class="n">myVocabList</span> <span class="o">=</span> <span class="n">createVocabList</span><span class="p">(</span><span class="n">listOPosts</span><span class="p">)</span>
    <span class="n">trainMat</span><span class="o">=</span><span class="p">[]</span>
    <span class="k">for</span> <span class="n">postinDoc</span> <span class="ow">in</span> <span class="n">listOPosts</span><span class="p">:</span>
        <span class="n">trainMat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">setOfWords2Vec</span><span class="p">(</span><span class="n">myVocabList</span><span class="p">,</span> <span class="n">postinDoc</span><span class="p">))</span>
    <span class="n">p0V</span><span class="p">,</span><span class="n">p1V</span><span class="p">,</span><span class="n">pAb</span> <span class="o">=</span> <span class="n">trainNB0</span><span class="p">(</span><span class="n">array</span><span class="p">(</span><span class="n">trainMat</span><span class="p">),</span><span class="n">array</span><span class="p">(</span><span class="n">listClasses</span><span class="p">))</span>
    <span class="n">testEntry</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;love&#39;</span><span class="p">,</span> <span class="s1">&#39;my&#39;</span><span class="p">,</span> <span class="s1">&#39;dalmation&#39;</span><span class="p">]</span>
    <span class="n">thisDoc</span> <span class="o">=</span> <span class="n">array</span><span class="p">(</span><span class="n">setOfWords2Vec</span><span class="p">(</span><span class="n">myVocabList</span><span class="p">,</span> <span class="n">testEntry</span><span class="p">))</span>
    <span class="nb">print</span> <span class="n">testEntry</span><span class="p">,</span><span class="s1">&#39;classified as: &#39;</span><span class="p">,</span><span class="n">classifyNB</span><span class="p">(</span><span class="n">thisDoc</span><span class="p">,</span><span class="n">p0V</span><span class="p">,</span><span class="n">p1V</span><span class="p">,</span><span class="n">pAb</span><span class="p">)</span>
    <span class="n">testEntry</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;stupid&#39;</span><span class="p">,</span> <span class="s1">&#39;garbage&#39;</span><span class="p">]</span>
    <span class="n">thisDoc</span> <span class="o">=</span> <span class="n">array</span><span class="p">(</span><span class="n">setOfWords2Vec</span><span class="p">(</span><span class="n">myVocabList</span><span class="p">,</span> <span class="n">testEntry</span><span class="p">))</span>
    <span class="nb">print</span> <span class="n">testEntry</span><span class="p">,</span><span class="s1">&#39;classified as: &#39;</span><span class="p">,</span><span class="n">classifyNB</span><span class="p">(</span><span class="n">thisDoc</span><span class="p">,</span><span class="n">p0V</span><span class="p">,</span><span class="n">p1V</span><span class="p">,</span><span class="n">pAb</span><span class="p">)</span>
</pre></div>
</div>
<p>整体来说，朴素贝叶斯分类方法在数据较少的情况下仍然有效，但是对数据输入比较敏感。</p>
</div>
<div class="section" id="logistic">
<h3>Logistic回归<a class="headerlink" href="#logistic" title="永久链接至标题">¶</a></h3>
<p>在统计学中，线性回归是利用称为线性回归方程的最小二乘函数对一个或多个自变量和因变量之间关系进行建模的一种回归分析。这种函数是一个或多个称为回归系数的模型参数的线性组合。只有一个自变量的情况称为简单回归，大于一个自变量情况的叫做多元回归。（ <a class="reference external" href="https://zh.wikipedia.org/zh-cn/%E7%B7%9A%E6%80%A7%E5%9B%9E%E6%AD%B8">维基百科</a> ）</p>
<p>先介绍两个重要的数学概念。</p>
<p><strong>最小二乘法则</strong></p>
<p>最小二乘法（又称最小平方法）是一种数学优化技术。它通过最小化误差的平方和寻找数据的最佳函数匹配。</p>
<p>利用最小二乘法可以简便地求得未知的数据，并使得这些求得的数据与实际数据之间误差的平方和为最小。</p>
<p><em>示例1</em></p>
<p>有四个数据点(1,6)、(2,5)、(3,7)、(4,10)，我们希望找到一条直线y=a+bx与这四个点最匹配。</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}a+1b=6\\a+2b=5\\a+3b=7\\a+4b=10\end{aligned}\end{align} \]</div>
<p>采用最小二乘法使等号两边的方差尽可能小，也就是找出这个函数的最小值：</p>
<div class="math notranslate nohighlight">
\[S(a,b) = [6-(a+1b)]^2+[5-(a+2b)]^2+[7-(a+3b)]^2+[10-(a+4b)]^2\]</div>
<p>然后对S(a,b)求a,b的偏导数，使其为0得到：</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\cfrac{{\partial}S}{{\partial}a} = 0 = 8a+20b-56\\\cfrac{{\partial}S}{{\partial}b} = 0 = 20a+60b-154\end{aligned}\end{align} \]</div>
<p>这样就解出：</p>
<div class="math notranslate nohighlight">
\[a=3.5,b=1.4\]</div>
<p>所以直线y=3.5+1.4x是最佳的。</p>
<p><em>函数表示</em></p>
<div class="math notranslate nohighlight">
\[\min_{\vec{b}}{\sum^n_{i=1}}(y_m-y_i)^2\]</div>
<p><em>欧几里德表示</em></p>
<div class="math notranslate nohighlight">
\[\min_{ \vec{b} } \| \vec{y}_{m} ( \vec{b} ) - \vec{y} \|_{2}\]</div>
<p><em>线性函数模型</em></p>
<p>典型的一类函数模型是线性函数模型。最简单的线性式是</p>
<div class="math notranslate nohighlight">
\[y = b_0 + b_1 t\]</div>
<p>写成矩阵式，为</p>
<div class="math notranslate nohighlight">
\[\begin{split}\min_{b_0,b_1}\left\|\begin{pmatrix}1 &amp; t_1 \\ \vdots &amp; \vdots \\ 1 &amp; t_n  \end{pmatrix}\begin{pmatrix} b_0\\ b_1\end{pmatrix} - \begin{pmatrix} y_1 \\ \vdots \\ y_{n}\end{pmatrix}\right\|_{2} = \min_b\|Ab-Y\|_2\end{split}\]</div>
<p>直接给出该式的参数解：</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}b_1 = \frac{\sum_{i=1}^n t_iy_i - n \cdot \bar t \bar y}{\sum_{i=1}^n t_i^2- n \cdot (\bar t)^2}\\b_0 = \bar y - b_1 \bar t\end{aligned}\end{align} \]</div>
<p>其中</p>
<div class="math notranslate nohighlight">
\[\bar t = \frac{1}{n} \sum_{i=1}^n t_i\]</div>
<p>为t值的算术平均值。也可解得如下形式：</p>
<div class="math notranslate nohighlight">
\[b_1 = \frac{\sum_{i=1}^n (t_i - \bar t)(y_i - \bar y)}{\sum_{i=1}^n (t_i - \bar t)^2}\]</div>
<p><em>示例2</em></p>
<p>随机选定10艘战舰，并分析它们的长度与宽度，寻找它们长度与宽度之间的关系。由下面的描点图可以直观地看出，一艘战舰的长度（t）与宽度（y）基本呈线性关系。散点图如下：</p>
<img alt="../_images/04-02.png" class="align-center" src="../_images/04-02.png" />
<p>以下图表列出了各战舰的数据，随后步骤是采用最小二乘法确定两变量间的线性关系。</p>
<img alt="../_images/04-03.png" class="align-center" src="../_images/04-03.png" />
<p>仿照上面给出的例子</p>
<div class="math notranslate nohighlight">
\[\bar t = \frac {\sum_{i=1}^n t_i}{n} = \frac {1678}{10} = 167{.}8\]</div>
<p>并得到相应的</p>
<div class="math notranslate nohighlight">
\[\bar y = 18{.}41\]</div>
<p>然后确定b1</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}b_1 = \frac{\sum_{i=1}^n (t_i- \bar {t})(y_i - \bar y)}{\sum_{i=1}^n (t_i- \bar t)^2}\\= \frac{3287{.}820} {20391{.}60} = 0{.}1612 \;\end{aligned}\end{align} \]</div>
<p>可以看出，战舰的长度每变化1m，相对应的宽度便要变化16cm。并由下式得到常数项b0：</p>
<div class="math notranslate nohighlight">
\[b_0 = \bar y - b_1 \bar t = 18{.}41 - 0{.}1612 \cdot 167{.}8 = -8{.}6394\]</div>
<p>可以看出点的拟合非常好，长度和宽度的相关性大约为96.03％。 利用Matlab得到拟合直线：</p>
<img alt="../_images/04-04.png" class="align-center" src="../_images/04-04.png" />
<p><strong>Sigmoid函数</strong></p>
<p>Sigmoid函数具有单位阶跃函数的性质，公式表示为：</p>
<div class="math notranslate nohighlight">
\[\sigma (z)=\cfrac{1}{1+e^{-z}}\]</div>
<img alt="../_images/04-01.png" class="align-center" src="../_images/04-01.png" />
<p>我们将输入记为z，有下面的公式得出：</p>
<div class="math notranslate nohighlight">
\[z=w_0 x_0 + w_1 x_1 + w_2 x_2 + \dots + w_n x_n\]</div>
<p>使用向量写法：</p>
<div class="math notranslate nohighlight">
\[z=w^T x\]</div>
<p>其中向量x是分类器的输入数据，向量w就是我们要找到的最佳系数。</p>
<p><em>基于优化方法确定回归系数</em></p>
<p><strong>梯度上升/下降法</strong></p>
<p>梯度上升法/下降法的思想是：要找到函数的最大值，最好的方法是沿着该函数的梯度方向探寻，函数f(x,y)的梯度如下表示：</p>
<div class="math notranslate nohighlight">
\[\begin{split}{\nabla}f(x,y)=\begin{pmatrix} \cfrac{{\partial}f(x,y)}{{\partial}x} \\ \cfrac{{\partial}f(x,y)}{{\partial}y}\end{pmatrix}\end{split}\]</div>
<p>可以这样理解此算法：</p>
<blockquote>
<div>从前有一座山，一个懒人要爬山，他从山脚下的任意位置向山顶出发，并且知道等高线图的每个环上都有一个宿营点，他希望在这些宿营点之间修建一条笔直的路，并且路到两旁的宿营点的垂直距离差的平方和尽可能小。每到一个等高线圈，他都会根据他在上一个等高线的距离的变化量来调节他的在等高线上的位置，从而使公路满足要求。</div></blockquote>
<p>返回回归系数：</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span>def sigmoid(x):
    return 1.0/(1+math.exp(-x))

def gradAscent(dataMatIn, classLabels):
    dataMatrix = mat(dataMatIn)             #convert to NumPy matrix
    labelMat = mat(classLabels).transpose() #convert to NumPy matrix
    m,n = shape(dataMatrix)
    alpha = 0.001
    maxCycles = 500
    weights = ones((n,1))
    for k in range(maxCycles):              #heavy on matrix operations
        h = sigmoid(dataMatrix*weights)     #matrix mult
        error = (labelMat - h)              #vector subtraction
        weights = weights + alpha * dataMatrix.transpose()* error #matrix mult
    return weights

其中，误差值乘以矩阵的转秩代表梯度。
</pre></div>
</div>
<p>接下来，我们载入数据集尝试画出最佳拟合直线：</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="k">def</span> <span class="nf">plotBestFit</span><span class="p">(</span><span class="n">w</span><span class="p">):</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">getA</span><span class="p">()</span> <span class="c1"># 将矩阵转化为数组</span>
    <span class="n">dataMat</span><span class="p">,</span> <span class="n">labelMat</span> <span class="o">=</span> <span class="n">loadDataSet</span><span class="p">()</span>
    <span class="n">dataArr</span> <span class="o">=</span> <span class="n">array</span><span class="p">(</span><span class="n">dataMat</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">shape</span><span class="p">(</span><span class="n">dataArr</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">x2</span> <span class="o">=</span> <span class="n">x3</span> <span class="o">=</span> <span class="n">x4</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="n">labelMat</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">x1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dataArr</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">1</span><span class="p">]);</span> <span class="n">y1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dataArr</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
        <span class="k">else</span>
            <span class="n">x2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dataArr</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">1</span><span class="p">]);</span> <span class="n">y2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dataArr</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">markers</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">y2</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">arrange</span><span class="p">(</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">weight</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="n">weights</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;X1&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;X2&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>如果处理大量数据集时，可以使用批量数据集中的单个数据点进行系数更新，或者使用随机数据集的数据点，分别如下所示：</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">stocGradAscentBatch</span><span class="p">(</span><span class="n">dataMatrix</span><span class="p">,</span> <span class="n">classLabels</span><span class="p">):</span>
    <span class="n">m</span><span class="p">,</span><span class="n">n</span> <span class="o">=</span> <span class="n">shape</span><span class="p">(</span><span class="n">dataMatrix</span><span class="p">)</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.01</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">dataMatrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">weights</span><span class="p">))</span>
        <span class="n">error</span> <span class="o">=</span> <span class="n">classLabels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">h</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">error</span> <span class="o">*</span> <span class="n">dataMatrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">weights</span>

<span class="k">def</span> <span class="nf">stocGradAscentRand</span><span class="p">(</span><span class="n">dataMatrix</span><span class="p">,</span> <span class="n">classLabels</span><span class="p">,</span> <span class="n">numIter</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
    <span class="n">m</span><span class="p">,</span><span class="n">n</span> <span class="o">=</span> <span class="n">shape</span><span class="p">(</span><span class="n">dataMatrix</span><span class="p">)</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numIter</span><span class="p">)</span>
        <span class="n">dataIndex</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="mi">4</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="o">+</span><span class="n">j</span><span class="o">+</span><span class="n">i</span><span class="p">)</span><span class="o">+</span><span class="mf">0.01</span>    <span class="c1"># 调整</span>
            <span class="n">randIndex</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataIndex</span><span class="p">)))</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">dataMatrix</span><span class="p">[</span><span class="n">randIndex</span><span class="p">]</span><span class="o">*</span><span class="n">weights</span><span class="p">))</span>
            <span class="n">error</span> <span class="o">=</span> <span class="n">classLabels</span><span class="p">[</span><span class="n">randIndex</span><span class="p">]</span> <span class="o">-</span> <span class="n">h</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">error</span> <span class="o">*</span> <span class="n">dataMatrix</span><span class="p">[</span><span class="n">randIndex</span><span class="p">]</span>
            <span class="k">del</span><span class="p">(</span><span class="n">dataIndex</span><span class="p">[</span><span class="n">randIndex</span><span class="p">])</span>   <span class="c1"># 删除已选，防止重复选取</span>
</pre></div>
</div>
</div>
<div class="section" id="id7">
<h3>线性回归<a class="headerlink" href="#id7" title="永久链接至标题">¶</a></h3>
</div>
<div class="section" id="id8">
<h3>树回归<a class="headerlink" href="#id8" title="永久链接至标题">¶</a></h3>
</div>
<div class="section" id="svm">
<h3>SVM<a class="headerlink" href="#svm" title="永久链接至标题">¶</a></h3>
<p>SVM（Supprot Vector Machines）即支持向量机，完全理解其理论知识对数学要求较高，以笔者的二半吊子水平不足以完全应付，所以，我就培养下感性认识吧。</p>
<p>以下内容来自 <a class="reference external" href="http://bytesizebio.net/2014/02/05/support-vector-machines-explained-well/">向5岁孩子解释SVM</a> ：</p>
<p>桌子上有两种颜色的球，</p>
<img alt="../_images/svm1.png" class="align-center" src="../_images/svm1.png" />
<p>我们需要在中间摆一根棍子把它们分开，</p>
<img alt="../_images/svm2.png" class="align-center" src="../_images/svm2.png" />
<p>完美，那么再加点球，发现再找到一个合适位置的话比较难了（但仍然可以找到），</p>
<img alt="../_images/svm3.png" class="align-center" src="../_images/svm3.png" />
<p>SVM就是试图把棍放在最佳位置，好让在棍的两边有尽可能大的间隙，</p>
<img alt="../_images/svm4.png" class="align-center" src="../_images/svm4.png" />
<p>这根棍仍然可以分开它们，</p>
<img alt="../_images/svm5.png" class="align-center" src="../_images/svm5.png" />
<p>如果，这样摆呢？</p>
<img alt="../_images/svm6.png" class="align-center" src="../_images/svm6.png" />
<p>你怒拍桌子，将球高高弹起，然后向忍着水果那样在空中划过笔直的一刀。就这样分开了。</p>
<img alt="../_images/svm7.png" class="align-center" src="../_images/svm7.png" />
<p>那一瞬，球在另一个维度被完美分开了，像这样。</p>
<img alt="../_images/svm8.png" class="align-center" src="../_images/svm8.png" />
<p>再之后无聊的大人们，把这些球叫做 data，把棍子 叫做 classifier, 最大间隙的把戏叫做optimization， 拍桌子叫做kernelling, 那张纸叫做hyperplane。</p>
<p>以2维数据为例，即平面上的点，可以用直线分割，一般形式为y=ax+b，如果不可分割，我们就将其提高一个维度，分割线变成了分割面（超平面），写作：</p>
<div class="math notranslate nohighlight">
\[|w^T A+b|\]</div>
</div>
<div class="section" id="id10">
<h3>神经网络<a class="headerlink" href="#id10" title="永久链接至标题">¶</a></h3>
</div>
<div class="section" id="adaboost">
<h3>AdaBoost<a class="headerlink" href="#adaboost" title="永久链接至标题">¶</a></h3>
</div>
</div>
<div class="section" id="id11">
<h2>2.3 无监督学习<a class="headerlink" href="#id11" title="永久链接至标题">¶</a></h2>
<div class="section" id="id12">
<h3>K-均值聚类<a class="headerlink" href="#id12" title="永久链接至标题">¶</a></h3>
</div>
<div class="section" id="apriori">
<h3>Apriori关联分析<a class="headerlink" href="#apriori" title="永久链接至标题">¶</a></h3>
</div>
<div class="section" id="fp-growth">
<h3>FP-growth发现高频项<a class="headerlink" href="#fp-growth" title="永久链接至标题">¶</a></h3>
</div>
</div>
<div class="section" id="id13">
<h2>2.4 数据可视化<a class="headerlink" href="#id13" title="永久链接至标题">¶</a></h2>
<div class="section" id="id14">
<h3>数据统计<a class="headerlink" href="#id14" title="永久链接至标题">¶</a></h3>
<p><a class="reference external" href="http://pandas.pydata.org/">Pandas</a></p>
<p>Gephi</p>
<p>GraphViz</p>
<p>python-matplotlib</p>
<p>Microsoft Excel 2013 PowerView</p>
</div>
<div class="section" id="id15">
<h3>地理位置表示<a class="headerlink" href="#id15" title="永久链接至标题">¶</a></h3>
<p><a class="reference external" href="http://developer.baidu.com/map/index.php?title=%E9%A6%96%E9%A1%B5">百度地图API</a></p>
<p><a class="reference external" href="http://dev.maxmind.com/geoip/geoip2/geolite2/">MaxMind GeoIP</a></p>
<p>Microsoft Excel 2013 PowerView使用示例</p>
<p><a class="reference external" href="http://kartograph.org/">Kartograph</a></p>
</div>
</div>
<div class="section" id="id16">
<h2>2.5 学习工具<a class="headerlink" href="#id16" title="永久链接至标题">¶</a></h2>
<div class="section" id="online">
<h3>Online<a class="headerlink" href="#online" title="永久链接至标题">¶</a></h3>
</div>
<div class="section" id="gui">
<h3>GUI<a class="headerlink" href="#gui" title="永久链接至标题">¶</a></h3>
<p><a class="reference external" href="http://www.cs.waikato.ac.nz/">Weka</a></p>
<p><a class="reference external" href="https://moa.cms.waikato.ac.nz">MOA</a></p>
<p><a class="reference external" href="https://orange.biolab.si/">Orange</a></p>
<p><a class="reference external" href="https://www.knime.com/">KNIME</a></p>
</div>
<div class="section" id="library">
<h3>Library<a class="headerlink" href="#library" title="永久链接至标题">¶</a></h3>
<p><a class="reference external" href="http://spark.apache.org/mllib/">Spark MLlib</a></p>
<p><a class="reference external" href="http://scikit-learn.org/">SciKit</a></p>
<p><a class="reference external" href="http://www.nltk.org/">NLTK</a></p>
<p><a class="reference external" href="http://pybrain.org">pybrain</a></p>
<p><a class="reference external" href="https://github.com/tensorflow">tensorflow</a></p>
<p>pytorch</p>
<p>caffe</p>
<p>libsvm</p>
<p>numpy</p>
<p>matplotlib</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="ch03.html" class="btn btn-neutral float-right" title="第三章 ABM建模基础" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="ch01.html" class="btn btn-neutral" title="第一章 数据收集、统计" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, lofyer

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script type="text/javascript" src="../_static/translations.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    

  

  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>